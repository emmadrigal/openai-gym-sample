@book{sutton2018reinforcement,
	place={Cambridge, Massachusetts}, edition={2},
	title={Reinforcement Learning: An Introduction},
	url={http://incompleteideas.net/book/bookdraft2017nov5.pdf},
	publisher={The MIT Press},
	author={Sutton, Richard S
			and Barto, Andrew G}, year={2017}
}

@inproceedings{henderson2018deep,
	title={Deep reinforcement learning that matters},
	author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@article{deepmind2019,
	author    = {Gabriel Dulac, Arnold and
			Daniel J. Mankowitz and
			Todd Hester},
	title     = {Challenges of Real-World Reinforcement Learning},
	journal   = {CoRR},
	year      = {2019},
	url       = {http://arxiv.org/abs/1904.12901},
	archivePrefix = {arXiv},
	eprint    = {1904.12901},
	timestamp = {Tue, 25 Jun 2019 11:11:15 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1904-12901.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{microsoft_research_2018,
	title={The next challenges for reinforcement learning},
	url={https://www.microsoft.com/en-us/research/blog/next-challenges-reinforcement-learning/},
	journal={Microsoft Research},
	publisher={Microsoft},
	year={2018},
	month={Jan}}

@article{watkins1989learning,
	title={Learning from delayed rewards},
	author={Watkins, Christopher John Cornish Hellaby},
	year={1989},
	publisher={King's College, Cambridge}
}

@article{minh_dqn,
	author    = {Arun Nair and
			Praveen Srinivasan and
			Sam Blackwell and
			Cagdas Alcicek and
			Rory Fearon and
			Alessandro De Maria and
			Vedavyas Panneershelvam and
			Mustafa Suleyman and
			Charles Beattie and
			Stig Petersen and
			Shane Legg and
			Volodymyr Mnih and
			Koray Kavukcuoglu and
			David Silver},
	title     = {Massively Parallel Methods for Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1507.04296},
	year      = {2015},
	url       = {http://arxiv.org/abs/1507.04296},
	archivePrefix = {arXiv},
	eprint    = {1507.04296},
	timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/NairSBAFMPSBPLM15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{plappert2016kerasrl,
	author = {Matthias Plappert},
	title = {keras-rl},
	year = {2016},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/keras-rl/keras-rl}},
}

@misc{tensorforce,
	author       = {Kuhnle, Alexander and Schaarschmidt, Michael and Fricke, Kai},
	title        = {Tensorforce: a TensorFlow library for applied reinforcement learning},
	howpublished = {Web page},
	url          = {https://github.com/tensorforce/tensorforce},
	year         = {2017}
}

@misc{stable-baselines,
	author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
	title = {Stable Baselines},
	year = {2018},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@misc{TFAgents,
title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},
author = "{Sergio Guadarrama, Anoop Korattikara, Oscar Ramirez,
Pablo Castro, Ethan Holly, Sam Fishman, Ke Wang, Ekaterina Gonina, Neal Wu,
Efi Kokiopoulou, Luciano Sbaiz, Jamie Smith, Gábor Bartók, Jesse Berent,
Chris Harris, Vincent Vanhoucke, Eugene Brevdo}",
howpublished = {\url{https://github.com/tensorflow/agents}},
url = "https://github.com/tensorflow/agents",
year = 2018,
note = "[Online; accessed 25-June-2019]"
}

@inproceedings{mao2016resource,
	title={Resource management with deep reinforcement learning},
	author={Mao, Hongzi and Alizadeh, Mohammad and Menache, Ishai and Kandula, Srikanth},
	booktitle={Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
	pages={50--56},
	year={2016}
}

@article{arel2010reinforcement,
	title={Reinforcement learning-based multi-agent system for network traffic signal control},
	author={Arel, Itamar and Liu, Cong and Urbanik, Tom and Kohls, Airton G},
	journal={IET Intelligent Transport Systems},
	volume={4},
	number={2},
	pages={128--135},
	year={2010},
	publisher={IET}
}

@article{kober2013reinforcement,
	title={Reinforcement learning in robotics: A survey},
	author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
	journal={The International Journal of Robotics Research},
	volume={32},
	number={11},
	pages={1238--1274},
	year={2013},
	publisher={SAGE Publications Sage UK: London, England}
}

@article{levine2016end,
	title={End-to-end training of deep visuomotor policies},
	author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	journal={The Journal of Machine Learning Research},
	volume={17},
	number={1},
	pages={1334--1373},
	year={2016},
	publisher={JMLR. org}
}

@inproceedings{zheng2018drn,
	title={DRN: A deep reinforcement learning framework for news recommendation},
	author={Zheng, Guanjie and Zhang, Fuzheng and Zheng, Zihan and Xiang, Yang and Yuan, Nicholas Jing and Xie, Xing and Li, Zhenhui},
	booktitle={Proceedings of the 2018 World Wide Web Conference},
	pages={167--176},
	year={2018}
}

@inproceedings{jin2018real,
	title={Real-time bidding with multi-agent reinforcement learning in display advertising},
	author={Jin, Junqi and Song, Chengru and Li, Han and Gai, Kun and Wang, Jun and Zhang, Weinan},
	booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
	pages={2193--2201},
	year={2018}
}

@article{silver2016mastering,
	title={Mastering the game of Go with deep neural networks and tree search},
	author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
	journal={nature},
	volume={529},
	number={7587},
	pages={484--489},
	year={2016},
	publisher={Nature Publishing Group}
}

@article{silver2017alphago,
	title={AlphaGo Zero: Starting from scratch},
	author={Silver, David and Hassabis, Demis},
	journal={London, United Kingdom: Deepmind},
	year={2017}
}

@article{hausknecht_2015,
	author    = {Matthew J. Hausknecht and
			Peter Stone},
	title     = {Deep Recurrent Q-Learning for Partially Observable MDPs},
	journal   = {CoRR},
	volume    = {abs/1507.06527},
	year      = {2015},
	url       = {http://arxiv.org/abs/1507.06527},
	archivePrefix = {arXiv},
	eprint    = {1507.06527},
	timestamp = {Mon, 13 Aug 2018 16:48:38 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/HausknechtS15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ganin_2018,
	author    = {Yaroslav Ganin and
			Tejas Kulkarni and
			Igor Babuschkin and
			S. M. Ali Eslami and
			Oriol Vinyals},
	title     = {Synthesizing Programs for Images using Reinforced Adversarial Learning},
	journal   = {CoRR},
	volume    = {abs/1804.01118},
	year      = {2018},
	url       = {http://arxiv.org/abs/1804.01118},
	archivePrefix = {arXiv},
	eprint    = {1804.01118},
	timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1804-01118.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhou2017optimizing,
	title={Optimizing chemical reactions with deep reinforcement learning},
	author={Zhou, Zhenpeng and Li, Xiaocheng and Zare, Richard N},
	journal={ACS central science},
	volume={3},
	number={12},
	pages={1337--1344},
	year={2017},
	publisher={ACS Publications}
}

@incollection{NIPS2010_3964,
title = {Double Q-learning},
author = {Hado V. Hasselt},
booktitle = {Advances in Neural Information Processing Systems 23},
editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
pages = {2613--2621},
year = {2010},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/3964-double-q-learning.pdf}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

 @misc{wu_2017, title={OpenAI Baselines: ACKTR \& A2C}, url={https://openai.com/blog/baselines-acktr-a2c/}, journal={OpenAI}, author={Wu, Yuhuai and Mansimov, Elman and Liao, Shun and Radford, Alec and Schulman, John}, year={2017}, month={Aug}}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994},
  publisher={University of Cambridge, Department of Engineering Cambridge, UK}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}


@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  pages={4565--4573},
  year={2016}
}

@article{AndrychowiczWRS17,
  author    = {Marcin Andrychowicz and
               Filip Wolski and
               Alex Ray and
               Jonas Schneider and
               Rachel Fong and
               Peter Welinder and
               Bob McGrew and
               Josh Tobin and
               Pieter Abbeel and
               Wojciech Zaremba},
  title     = {Hindsight Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1707.01495},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.01495},
  archivePrefix = {arXiv},
  eprint    = {1707.01495},
  timestamp = {Fri, 08 Nov 2019 12:51:04 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/AndrychowiczWRS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{abs-1801-01290,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1801-01290.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dankwa2019twin,
  title={Twin-Delayed DDPG: A Deep Reinforcement Learning Technique to Model a Continuous Movement of an Intelligent Robot Agent},
  author={Dankwa, Stephen and Zheng, Wenfeng},
  booktitle={Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
  pages={1--5},
  year={2019}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@inproceedings{liang2018rllib,
  title={RLlib: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
    year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/ray-project/ray}},
}


@misc{kenggraesser2017slmlab,
    author = {Keng, Wah Loon and Graesser, Laura},
    title = {SLM Lab},
    year = {2017},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/kengz/SLM-Lab}},
}